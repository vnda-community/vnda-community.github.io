---
title: 'Góc nhìn đa chiều về công nghệ mới Deepfakes'
date: 2022-07-28
permalink: /post/2022-07-28-deepfakes/
header:
  overlay_image: ../images/banner.png
  overlay_filter: 0.1 # same as adding an opacity of 0.5 to a black background
  thumbnail: 2022-07-28-deepfakes/cover.png
tags:
  - Thị giác máy tính (Computer Vision)
image: /images/2022-07-28-deepfakes/cover.png
---

![Hình 1: Deepfakes: Thật hay giả?](/images/2022-07-28-deepfakes/cover.png){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 1: Deepfakes - Thật hay giả?</em>
</div>
<br>

## Deepfakes có gì hấp dẫn? 

Công nghệ Deepfakes đang trở thành chủ đề hấp dẫn cho giới công nghệ [(Joseph Foley, 2022)](https://www.creativebloq.com/features/deepfake-examples). 
Ban đầu, Deepfakes được xây dựng cho mục đích giải trí bằng cách tráo đổi khuôn mặt một nhân vật trong video thành người khác, nhưng hiện nay Deepfakes đã trở nên phổ biến trong các bô phim bom tấn hay các bản tin truyền hình. 
Để hiểu hơn về Deepfakes, các bạn hãy cùng xem những ví dụ sau nhé.

<iframe width="420" height="315" src="https://www.youtube.com/embed/WXeuEHhDPNI" frameborder="0" allowfullscreen></iframe>
<div style="text-align: center;">
<em>Video 1: Khuôn mặt của Tổng thống Donald Trump được ghép vào đoạn video của Joker. Ngài Tổng thống không hề nói những điều như trong video.</em>
</div>
<br>

<iframe width="420" height="315" src="https://www.youtube.com/embed/iyiOVUbsPcM" frameborder="0" allowfullscreen></iframe>
<div style="text-align: center;">
<em>Video 2: Khuôn mặt của tài tử Tom Cruise được chuyển vào video của người khác. Tom Cruise không hề đánh golf hay làm ảo thuật như trong video.</em>
</div>
<br>

## Công nghệ Deepfakes là gì?

Theo [Ivy Wigmore (2020)](https://www.techtarget.com/whatis/definition/deepfake), Deepfakes là một dạng AI (trí tuệ nhân tạo) tạo ra những hình ảnh, âm thanh, hay video giả chân thật. 
Tên gọi Deepfakes được kết hợp từ Deep learning (học sâu) và Fakes (giả).

Deepfakes được xây dựng trên 2 thuật toán AI là Generator và Discriminator. 
Hai thuật toán này sẽ tương tác với nhau để tạo ra những video Deepfakes như chúng ta đã thấy.

Generator và Discriminator hợp lại tạo thành [GAN (Generative Adversarial Network)](https://arxiv.org/abs/1406.2661). 
Để tạo ra GAN, chúng ta cần xác định sản phẩm cuối cùng trông như thế nào, đồng thời huấn luyện Generator với một lượng dữ liệu lớn. 
Từ đó, Generator sẽ tạo ra nội dung giả định, và Discriminator sẽ xác định liệu nội dung vừa được tạo ra trông thật hay không. 
Mỗi lần Discriminator xác định nội dung tạo ra trông không thật, Generator sẽ nhận thông tin này và tạo ra nội dung mẫu tiếp theo tốt hơn. 
Quy trình này tiếp tục cho đến khi chúng ta nhận được đoạn video ưng ý. 

![Hình 2: Mô hình Generative Adversarial Network (GAN). Nguồn: https://sthalles.github.io/intro-to-gans/](/images/2022-07-28-deepfakes/gan.png){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 2: Mô hình Generative Adversarial Network (GAN). Nguồn: https://sthalles.github.io/intro-to-gans/</em>
</div>
<br>

## Sử dụng Deepfakes đơn giản như thế nào?
Theo như bài viết của [Geoffrey Fowler (2021)](https://www.washingtonpost.com/technology/2021/03/25/deepfake-video-apps/), các thuật toán phía sau Deepfakes có vẻ phức tạp, nhưng thật ra việc sử dụng công nghệ Deepfakes vô cùng đơn giản. 
Người dùng không cần hiểu Deepfakes là gì, ứng dụng Avatarify trên Iphone dễ dàng thay đổi khuôn mặt người trong video thành một người khác. Mặc dù Avatarify vẫn còn nhiều hạn chế, nhưng đã được tải về hơn 6 triệu lần. 
Các bạn có thể tham khảo app Avatarify theo link dưới đây:

![Hình 3: Ứng dụng Avatarify giúp tạo ra Deepfakes một cách dễ dàng.](/images/2022-07-28-deepfakes/avatarify.jpeg){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 3: Ứng dụng Avatarify giúp tạo ra Deepfakes một cách dễ dàng.</em>
</div>
<br>

Một ứng dụng phổ biến khác là MyHeritage cho phép người dùng sử dụng Deepfakes để đưa hình người đã khuất trở nên sống lại. 
Người dùng chỉ cần tải lên ảnh của người thân/ bạn đã mất, MyHeritage sẽ tạo ra những video ngắn những người đã mất cử động, thậm chí là cười. 
Nhiều người nhận xét những vết nhăn quanh mắt trông rất thật. Tính năng này được gọi là “Deep Nostalgia”. 
Các bạn có thể tham khảo thêm về MyHeritage theo link sau:

<iframe width="420" height="315" src="https://www.youtube.com/embed/kEtiajHLmQY" frameborder="0" allowfullscreen></iframe>
<div style="text-align: center;">
<em>Video 3: MyHeritage cho phép người dùng sử dụng Deepfakes để đưa hình người đã khuất trở nên sống lại</em>
</div>
<br>

## Ưu điểm của Deepfakes
Theo diễn giả [Richard van Hooijdonk](https://blog.richardvanhooijdonk.com/en/the-good-the-bad-and-the-future-of-deepfakes/), Deepfakes cho phép chúng ta trải nghiệm những điều chưa từng có, hoặc trải nghiệm những khả năng trong tương lai. 
Deepfakes có những ứng dụng tiềm năng trong nhiều lĩnh vực chẳng hạn như giải trí, truyền hình, và giao tiếp.

Deepfakes có thể điều chỉnh giọng nói dễ dàng như cách chúng ta chỉnh sửa hình ảnh. Cụ thể hơn, Synthesia, một công ty trí tuệ nhân tạo thành lập bởi nhóm nhà nghiên cứu và khởi nghiệp từ Stanford, University College London, Cambridge, và Technical University of Munich. Synthesia tiên phong trong một phương pháp truyền hình mới: phần mềm kiểm soát khuôn mặt (facial re-animation software). Synthesia được sử dụng trong việc đọc tin tức tự động chỉ bằng sử dụng bản thảo chữ viết và nguồn video của người dẫn chương trình. 

<iframe width="420" height="315" src="https://www.youtube.com/embed/kbmupakG2tQ" frameborder="0" allowfullscreen></iframe>
<div style="text-align: center;">
<em>Video 4: Video hướng dẫn về Synthesia</em>
</div>
<br>

Trợ lí ảo thông minh như Siri, Alexa, và Cortana xuất hiện từ lâu và đang phát triển mạnh những năm gần đây. 
Tuy nhiên, những trợ lí ảo này vẫn mang lại cảm giác không thật (người dùng phải đưa ra mệnh lệnh chính xác). 
Nhưng Deepfakes có thể nâng cấp những hệ thống này bằng cách tự tái tạo khuôn mặt, biểu cảm, và giọng nói của một người nào đó. 
Điều này giúp trợ lí ảo giao tiếp giống người hơn trong tương lai.

## Mặt trái của Deepfakes
Theo [Ashish Jaiman (2020)](https://towardsdatascience.com/deepfakes-harms-and-threat-modeling-c09cbe0b7883), bên cạnh những mặt tốt, có nhiều vấn đề đáng lo ngại liên quan đến công nghệ Deepfakes. 

Đầu tiên, 96% các video sử dụng Deepfakes có liên quan đến nội dung khiêu dâm, chủ yếu nhắm vào phụ nữ. Vào năm 2018, Rana Ayyub, một nhà báo ở Mumbai (Ấn Độ) phát hiện một đoạn video phim người lớn xuất hiện hình ảnh của cô dù cô chưa từng làm những chuyện như vậy. Đoạn video nhanh chóng lan truyền khắp mạng xã hội, và mọi người thay nhau thóa mạ và sỉ nhục cô. Áp lực quá lớn khiến cô phải nhập viện trong tình trạng nguy hiểm. 

Một trào lưu nguy hiểm khác là một số người sử dụng Deepfakes để tạo ra đoạn phim người lớn thay đổi khuôn mặt của những người nổi tiếng như Taylor Swift hay Emma Watson. Hành vi này có thể hủy hoại sự nghiệp người nghệ sĩ khi họ vẫn loay hoay chứng minh sự trong sạch của mình.

Ngoài ra, Deepfakes có thể làm giảm uy tín của ngành báo chí bởi mọi người không phân biết đâu là thông tin chính xác, đâu là thông tin đã chỉnh sửa bởi Deepfakes. Nhiều video giả được sử dụng ở Myanmar và Ấn Độ nhằm mục đích bôi nhọ và đàn áp người đạo Hồi.

Cuối cùng, Deepfakes có thể ảnh hưởng tiêu cực tới kết quả bầu cử. Ví dụ, một video trong đó ứng viên tranh cử có những hành động phạm pháp được tung ra vài ngày trước bầu cử. Điều này sẽ phá tan nỗ lực cả chiến dịch của họ, bởi không có đủ thời gian để minh oan cho bản thân trước khi người dân đi bỏ phiếu.

## Trách nhiệm kiểm soát Deepfakes
Kiểm soát Deepfakes là điều vô cùng cần thiết. Nếu không, chúng ta sẽ phải đối mặt với nhiều hệ lụy của nó. Trách nhiệm kiểm soát Deepfakes cần sự phối hợp chặt chẽ từ chính quyền, công ty công nghệ, công ty an ninh mạng, doanh nghiệp, và cả người sử dụng.

Đối diện chính phủ, việc ban hành luật lệ ngăn chặn Deepfakes ảnh hưởng đến hoạt động dân chủ, hoạt động doanh nghiệp, và đời sống người dân là quan trọng. Ví dụ như tại bang California (Mỹ), 2 dự thảo đã được đưa ra từ năm ngoái. Thứ nhất là dự thảo AB-602 cấm việc sử dụng hình ảnh người khác trong phim ảnh có nội dung khiêu dâm mà không có sự đồng ý của đối tượng. Và dự luật thứ hai là AB-730 cấm việc điều chỉnh hình ảnh của ứng viên tranh cử trong vòng 60 ngày trước bầu cử ([Kaspersky](https://www.kaspersky.com/resource-center/threats/protect-yourself-from-deep-fake)).

Đối với các công ty công nghệ lớn, việc bảo vệ người dùng khỏi tác động của Deepfakes là bước đi đúng đắn. Facebook thông báo xóa toàn bộ những video chỉnh sửa bởi Deepfakes ra khỏi hệ thống ([Sam Shead, 2020](https://www.bbc.com/news/technology-51018758)) vì những video này làm thay đổi thực tế và tạo ra mối nguy đến ngành công nghệ. Những video mà những sự chỉnh sửa của nó là không rõ ràng với người bình thường, hoặc gây nhầm lẫn tai hại, có yếu tố khiêu dâm bạo lực, làm nhiều loạn người bầu cử và yếu tố hằn học đều sẽ bị xóa bỏ. Tương tự Facebook, Google cũng đã cấm việc huấn luyện AI cho Deepfakes trên Google Colaboratory nơi mà mọi người có thể viết và thử các thuật toán Python ([Kyle Wiggers, 2022](https://techcrunch.com/2022/06/01/2328459/)). Vì thế, DeepfaceLab không thể tiếp tục thực hiện dự án liên quan tới Deepfakes trên Cobaloratory. Tuy nhiên, một số dự án liên quan đến Deepfakes khác như FaceSwap vẫn có thể hoạt động bình thường. Điều này có nghĩa chính sách của Google hiện nay dựa trên danh sách đen (blacklist) thay vì chọn lọc các từ khóa chính. 

Rất may mắn là các công ty an ninh mạng đang phát triển các thuật toán phát hiện Deepfakes tinh vi hơn. Những thuật toán này phân tích hình ảnh video, và có thể phát hiện những thay đổi nhỏ đã được tạo ra trong quá trình làm giả, ví dụ có thể nhận thấy sự khác nhau của sống mũi. Ngoài ra, thuật toán sử dụng công nghệ cryptography có thể được sử dụng để thêm vào các hashes cho mỗi phân đoạn trong video. Điều này có nghĩa nếu video thay đổi, hashes cũng sẽ thay đổi. Từ đó, AI và blockchain có thể dán dấu vân tay điện tử cho video, tương tự như việc đóng dấu tài liệu. Do đó, chúng ta dễ dàng nhận ra video đã qua chỉnh sửa Deepfakes. Vấn đề khó ở đây là đảm bảo hashes có khả năng tồn tại nếu video bị nén lại.

Đối với mỗi cá nhân, việc nhận biết được thông tin nào là chính xác rất quan trọng trong việc bảo vệ bản thân mình. Một số dấu hiệu trong video chúng ta có thể chú ý là: cử động lắc lư của nhân vật, thay đổi ánh sáng khi đổi khung hình, thay đổi màu da, mắt nhấp nháy không bình thường, hay môi không khớp với giọng nói.

## Kết luận
Có thể thấy Deepfakes là công nghệ tương lai với rất nhiều lợi ích hứa hẹn cho toàn xã hội. Tuy nhiên cũng như như phát minh công nghệ khác, Deepfakes cũng có những mặt trái đáng lo ngại của nó. Vì thế chúng ta cần sự hợp tác của nhiều đơn vị có liên quan để giảm thiểu rủi ro của Deepfakes.
