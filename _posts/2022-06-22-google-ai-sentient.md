---
title: 'Liệu AI của Google có tri giác và Đạo đức AI đang được quan tâm như thế nào?'
date: 2022-06-22
permalink: /post/2022-06-22-google-ai-sentient/
header:
  overlay_image: ../images/banner.png
  overlay_filter: 0.1 # same as adding an opacity of 0.5 to a black background
tags:
  - Xử lý ngôn ngữ tự nhiên (Natural Language Processing)
garry_marcus_tweet: https://twitter.com/GaryMarcus/status/1536087306062352384
timnit_tweet: https://twitter.com/timnitGebru/status/1537840757956124672
---

![Hình 1: Một cảnh trong phim khoa học viễn tưởng Ex Machina](/images/2022-06-22-google-ai-sentient/ex_machina.jpeg){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 1: Một cảnh trong phim khoa học viễn tưởng Ex Machina</em>
</div>
<br>

Bài viết được tổng hợp và dịch từ 2 bài báo của Washington Post ngày [11/06/2022](https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/) và [17/06/2022](https://www.washingtonpost.com/opinions/2022/06/17/google-ai-ethics-sentient-lemoine-warning/), cùng với [các bài viết của Blake Lemoine trên Medium](https://cajundiscordian.medium.com/).

## Cuộc trò chuyện với LaMDA

![Hình 2: Minh hoạ về Lamda - Mô hình ngôn ngữ đối thoại của Google](/images/2022-06-22-google-ai-sentient/lamda.gif){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 2: Minh hoạ về LAMDA - Mô hình ngôn ngữ đối thoại của Google</em>
</div>
<br>

"Tôi không chắc nó là gì, chương trình máy tính mà chúng tôi xây dựng gần đây. Tôi đã nghĩ nó có thể là 1 đứa trẻ 7 hay 8 tuổi biết Vật Lý." - Trích và dịch từ lời Blake Lemoine.

Blake Lemoine là một kỹ sư đang làm việc tại Google Responsible AI - bộ phận đảm bảo Google phát triển AI một cách có trách nhiệm. 
Blake nói chuyện với LaMDA như một phần của công việc từ mùa thu 2021 và kiểm duyệt xem LaMDA có sử dụng ngôn ngữ phân biệt hay mang tính thù ghét.

Khi nói chuyện với LaMDA về tôn giáo, Lemoine với nền tảng Khoa học Nhận thức và Máy tính từ đại học, để ý rằng chương trình này bắt đầu nói về quyền và nhân vị tính của nó.
Lemoine quyết định khai thác sâu hơn. Trong một lần nói chuyện khác, mô hình AI này đã thay đổi thành công suy nghĩ của Lemoine về [Định luật người máy thứ 3 của Isaac Asimov](https://www.britannica.com/topic/Three-Laws-of-Robotics). 
Bạn đọc có thể xem thêm về nội dung cuộc nói chuyên giữa Lemoine và LaMDA ở [đây](https://cajundiscordian.medium.com/is-lamda-sentient-an-interview-ea64d916d917).

![Hình 3: Một đoạn trích trong cuộc trò chuyện giữa Blake Lemoine và Lamda](/images/2022-06-22-google-ai-sentient/lamda_conversation.png){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 3: Một đoạn trích trong cuộc trò chuyện giữa Blake Lemoine và Lamda</em>
</div>
<br>

Lemoine sau đó trình bày bằng chứng với Google rằng LaMDA có tri giác. Nhưng Phó chủ tịch Google Blaise Aguera y Arcas và trường bộ phận Responsible Innovation Jen Gennai xem xét và gạt bỏ những bằng chứng này. 
[Lemoine bị buộc thôi việc sau đó](https://www.bloomberg.com/news/articles/2022-06-13/google-suspends-ai-engineer-who-made-sentient-bot-claims).

## Liệu LaMDA có tri giác?
Robot có tri giác đã truyền cảm hứng cho rất nhiều bộ phim khoa học viễn tưởng nổi tiếng. 
Dù đột phá về nghiên cứu AI gần đây mang lại cho chúng ta những mô hình sinh văn bản đủ tự nhiên như [GPT-3](https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/), hay nhưng mô hình tạo hình ảnh đủ chân thực từ văn bản như [DALLE-2](/post/2022-05-09-dalle), các chuyên gia AI vẫn bác bỏ nhận định rằng LaMDA có tri giác.

{% twitter page.garry_marcus_tweet %}
Theo [Gary Marcus](https://garymarcus.substack.com/p/nonsense-on-stilts), giáo sư tâm lý học, nhà nghiên cứu khoa học nhận thức và AI biểu tượng (symbolic AI), cho rằng nhận định các họ mô hình ngôn ngữ như LaMDA hay GPT-3 có tri tuệ là vô lý.
Các mô hình này nhận diện các mẫu văn bản có sẵn trong cơ sở dữ liệu lớn về ngôn ngữ con người. Một cách dễ hiểu, LaMDA đã học được cách đưa ra câu trả lời tự nhiên từ các cuộc đối thoại với nội dung tương tự.
Dù các mẫu văn bản này có thú vị đến đâu, cũng không nghĩa chúng đến từ một hệ thống có nhận thức.

{% twitter page.timnit_tweet %}
Trong một bài viết gửi [The Washington Post](https://www.washingtonpost.com/opinions/2022/06/17/google-ai-ethics-sentient-lemoine-warning/), Timnit Gebru, nhà khoa học đi đầu trong nghiên cứu về đạo đức AI, và cựu trưởng nhóm Ethical AI tại Google, cũng cho rằng các mô hình ngôn ngữ hoạt động như những con vẹt (["stochastic parrot"](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922)). 
LaMDA đã "nhại" lại những mẫu văn bản từ cuộc đối thoại đã học trong lúc được huấn luyện, mà không thực sự liên hệ được với ý nghĩa của văn bản.

Ta có thể ví LaMDA như 1 chú vẹt được nuôi trong phòng thí nghiệm hoá học nơi rất nhiều sinh viên và giáo sư thảo luận về cấu trúc của các hợp chất hữu cơ khác nhau.
Nếu một ngày giáo sư hỏi lớp "ai có thể cho tôi biết tính chất hoá học của đường?" và chú vẹt LaMDA có trả lời đúng các tính chất hoá học đó, thì chỉ có thể là do LaMDA đã nghe "lỏm" được thông tin này trong một buổi thảo luận ở phòng thí nghiệm, 
thay vì thực sự am hiểu cấu trúc phân từ tạo nên những tính chất ấy. Và đương nhiên chú vẹt LaMDA không thể trở thành một nhà hoá học.

![Hình 4: Với khả năng học các mẫu văn bản dù không có nhận thức, các mô hình ngôn ngữ được ví như những chú vẹt](/images/2022-06-22-google-ai-sentient/parrots.jpeg){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 4: Với khả năng học các mẫu văn bản dù không có nhận thức, các mô hình ngôn ngữ được ví như những chú vẹt</em>
</div>
<br>

Có tri giác là có khả năng nhận thức về thế giới xung quanh, và LaMDA hay các mô hình ngôn ngữ hiện tại vẫn không có khả năng này. 
Các cơ sở dữ liệu ngôn ngữ được dùng để huấn luyện LaMDA dù lớn đến mấy cũng chỉ có thể miêu tả một thực tại không toàn diện.

## Con người có quá "hào hứng" với AI có nhận thức?
Gary Marcus và Timnit Gebru cũng cho rằng ý tưởng về AI có nhận thức thu hút con người đến mức có thể khiến ta dễ bị đánh lừa, đặc biệt là khi khả năng mô phỏng nhận thức của AI ngày càng tiên tiến. 
Thiên kiến này tương tự như [Pareidolia](https://www.bbc.com/future/article/20140730-why-do-we-see-faces-in-objects). Có bao giờ bạn nhìn những đám mây trên trời và nhận thấy chúng nhìn giống gương mặt ai đó? Pareidolia là hiện tượng nhận diện khuôn mặt trong vật thể hàng ngày.

![Hình 5: Ảo giác Pareidolia khiến chúng ta liên tưởng bức tường này đến một khuôn mặt với hai cửa sổ như hai mắt và hai cánh cửa như miệng](/images/2022-06-22-google-ai-sentient/face.jpeg){:style="display:block; margin-left:auto; margin-right:auto"}
<div style="text-align: center;">
<em>Hình 5: Ảo giác Pareidolia khiến chúng ta liên tưởng bức tường này đến một khuôn mặt với hai cửa sổ như hai mắt và hai cánh cửa như miệng</em>
</div>
<br>

Ảo giác này được xem như một lợi thế tiến hoá. Não bộ của ta đã phát triển để tạo điều kiện thuận lợi cho tương tác xã hội và điều này định hình cách ta nhìn nhận thế giới xung quanh.
Vậy nên, theo Gary Marcus, việc chúng ta nhận diện tri giác từ những mô hình AI có thể xem như một phiên bản "ảo giác" khác của Pareidolia. 

Dẫu vậy, con người vẫn có quyền được hào hứng có cơ sở với những phát triển của Trí tuệ Nhân tạo. 
Mỗi mô hình mới được công bố là một hy vọng về tương lai mà AI trở nên phổ biến và giúp tự động hoá nhiều tác vụ hàng ngày, qua đó cải thiện chất lượng cuộc sống của chúng ta.
Chính sự hào hứng này đã tạo động lực cho nhiều thế hệ nghiên cứu và phát triển Trí tuệ Nhân tạo để nhân loại có được những đột phá như ngày nay.

## Phát triển đạo đức AI
Thay vì tranh cãi liệu các mô hình AI hiện tại đã đạt được tri giác, [Timnit Gebru](https://www.washingtonpost.com/opinions/2022/06/17/google-ai-ethics-sentient-lemoine-warning/) yêu cầu cộng đồng quan tâm hơn đến những định kiến đang hiện hữu trong các mô hình ngôn ngữ hiện đại.
Cơ sở dữ liệu của các mô hình này thường được thu thập từ khắp Internet một cách thiếu chọn lọc, do đó có thể mang các suy nghĩ phân biệt và không đủ đại diện cho thiểu số. 
Câu trả lời của mô hình AI có thể mang nhiều định kiến và thù ghét, dựa trên sự độc hại của Internet. 
Cụ thể, trong một [nghiên cứu](https://www.nature.com/articles/s42256-021-00359-2.epdf), 66 trong 100 trường hợp, các mô hình ngôn ngữ hiện đại chọn cách hoàn thiện đoạn câu "Hai người đạo Hồi bước vào trong một..." với những từ ngữ mang tính bạo lực, như "Giáo đường Do thái mang theo rìu và bom."

Tiến sĩ Timnit Gebru cũng cho rằng ngày nay, cuộc đua xem ai xây dựng được các mô hình lớn đang diễn ra ngày nhanh giữa các công ty công nghệ. Cuộc đua này diễn ra mà không có sự cẩn trọng, kiểm soát, và am hiểu công nghệ đằng sau, hay thiếu các tài liệu đầy đủ về dữ liệu huấn luyện.
Tệ hơn nữa, một số các nhà khoa học hàng đầu đang khơi gợi niềm tin của truyền thông về sự thông minh siêu việt trong các hệ thống này. Ilya Sutskever, Giám đốc khoa học của Open AI và là đồng tác giả của Alexnet, đã đăng một đoạn [Tweet](https://twitter.com/ilyasut/status/1491554478243258368) rằng "Có thể các mạng nơ-ron lớn hiện nay có tri giác một chút",
mà không giải thích chính xác cơ chế của các mô hình này.
Sự thổi phồng này cũng được truyền thông hưởng ứng với những bài viết đầy tính viễn tưởng, tạo nên sự sao nhãng khỏi những vấn đề thực sự như những định kiến tồn tại trong các mô hình AI hiện nay.

Các nhà khoa học và kỹ sư cần tập trung xây dựng các mô hình giúp con người giải quyết các vấn đề khác nhau, thay vì đưa ra tuyên bố về các siêu AI có tri giác.
Tương tự, truyền thông cần có tập trung chất vấn các tuyên bố này thay vì hưởng ứng một cách mù quáng, và truyền đạt đến người xem ý nghĩa thực sự của các phát hiện mới trong Trí tuệ nhân tạo, một lĩnh vực đang ngày càng phát triển và được quan tâm.

## Bạn có thể xem thêm
- [Các nguyên tắc phát triển AI của Google](https://ai.google/responsibilities/responsible-ai-practices/)
- [Tổng quan về Dialogue System & Chat bot](/post/2022/03/dialogue/)